{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.douban.com/simple\n",
      "Collecting keras==2.1.6\n",
      "  Using cached https://pypi.doubanio.com/packages/54/e8/eaff7a09349ae9bd40d3ebaf028b49f5e2392c771f294910f75bb608b241/Keras-2.1.6-py2.py3-none-any.whl (339 kB)\n",
      "Requirement already satisfied: h5py in /Users/hui/anaconda3/envs/tf1/lib/python3.6/site-packages (from keras==2.1.6) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/hui/anaconda3/envs/tf1/lib/python3.6/site-packages (from keras==2.1.6) (1.4.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/hui/anaconda3/envs/tf1/lib/python3.6/site-packages (from keras==2.1.6) (1.14.0)\n",
      "Requirement already satisfied: pyyaml in /Users/hui/anaconda3/envs/tf1/lib/python3.6/site-packages (from keras==2.1.6) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/hui/anaconda3/envs/tf1/lib/python3.6/site-packages (from keras==2.1.6) (1.16.2)\n",
      "\u001b[31mERROR: seqeval 0.0.12 has requirement Keras>=2.2.4, but you'll have keras 2.1.6 which is incompatible.\u001b[0m\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.1.6\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.1.6 -i https://pypi.douban.com/simple --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# 这部分返回一个张量\n",
    "inputs = Input(shape=(784,))\n",
    "\n",
    "# 层的实例是可调用的，它以张量为参数，并且返回一个张量\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# 这部分创建了一个包含输入层和三个全连接层的模型\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras中文官网：https://keras.io/zh/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras简单建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T02:08:14.367420Z",
     "start_time": "2020-08-23T02:08:14.118143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 784, 200)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "embedding_18 (Embedding)     (None, 784, 200)          156800    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 784, 64)           12864     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 784, 64)           4160      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 784, 10)           650       \n",
      "=================================================================\n",
      "Total params: 174,474\n",
      "Trainable params: 174,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hui/anaconda3/envs/tf1/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Reshape\n",
    "\n",
    "# 定义输入层\n",
    "input = Input(shape=(784,))\n",
    "# 嵌入层\n",
    "embedding = Embedding(784, 200, input_length=None)(input)\n",
    "print(embedding.shape)\n",
    "# embedding = Reshape((200,))(embedding)\n",
    "\n",
    "# 定义各个连接层，包括两个全连接层，使用relu和softmax激活函数\n",
    "layer1 = Dense(64, activation='relu')(embedding)\n",
    "layer2 = Dense(64, activation='relu')(layer1)\n",
    "\n",
    "# 定义输出层\n",
    "out = Dense(10, activation='softmax')(layer2)\n",
    "\n",
    "# 定义模型对象\n",
    "model = Model(inputs=input, output=out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding\n",
    "\n",
    "将正整数（索引值）转换为固定尺寸的稠密向量。 例如： [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\n",
    "\n",
    "该层只能用作模型中的第一层。\n",
    "\n",
    "```python\n",
    "keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)\n",
    "```\n",
    "\n",
    "#### 参数\n",
    "- input_dim: int > 0。词汇表大小， 即，最大整数 index + 1。\n",
    "- output_dim: int >= 0。词向量的维度。\n",
    "- embeddings_initializer: embeddings 矩阵的初始化方法 (详见 initializers)。\n",
    "- embeddings_regularizer: embeddings matrix 的正则化方法 (详见 regularizer)。\n",
    "- embeddings_constraint: embeddings matrix 的约束函数 (详见 constraints)。\n",
    "- mask_zero: 是否把 0 看作为一个应该被遮蔽的特殊的 \"padding\" 值。 这对于可变长的 循环神经网络层 十分有用。 如果设定为 True，那么接下来的所有层都必须支持 masking，否则就会抛出异常。 如果 mask_zero 为 True，作为结果，索引 0 就不能被用于词汇表中 （input_dim 应该与 vocabulary + 1 大小相同）。\n",
    "- input_length: 输入序列的长度，当它是固定的时。 如果你需要连接 Flatten 和 Dense 层，则这个参数是必须的 （没有它，dense 层的输出尺寸就无法计算）。\n",
    "\n",
    "#### 输入尺寸\n",
    "尺寸为 (batch_size, sequence_length) 的 2D 张量。\n",
    "\n",
    "#### 输出尺寸\n",
    "尺寸为 (batch_size, sequence_length, output_dim) 的 3D 张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T09:31:12.181329Z",
     "start_time": "2020-08-23T09:31:11.364516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 10)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=1000, output_dim=64, input_length=10))\n",
    "# 模型将输入一个大小为 (batch, input_length) 的整数矩阵。\n",
    "# 输入中最大的整数（即词索引）不应该大于 999 （词汇表大小）\n",
    "# 现在 model.output_shape == (None, 10, 64)，其中 None 是 batch 的维度。\n",
    "\n",
    "input_array = np.random.randint(1000, size=(32, 10))\n",
    "print(input_array.shape)\n",
    "\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "print(output_array.shape == (32, 10, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense\n",
    "\n",
    "```python\n",
    "keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
    "```\n",
    "就是你常用的的全连接层。\n",
    "\n",
    "Dense 实现以下操作： output = activation(dot(input, kernel) + bias) 其中 activation 是按逐个元素计算的激活函数，kernel 是由网络层创建的权值矩阵，以及 bias 是其创建的偏置向量 (只在 use_bias 为 True 时才有用)。\n",
    "\n",
    "注意: 如果该层的输入的秩大于2，那么它首先被展平然后 再计算与 kernel 的点乘。\n",
    "\n",
    "### 参数\n",
    "- units: 正整数，输出空间维度。\n",
    "- activation: 激活函数 (详见 activations)。 若不指定，则不使用激活函数 (即，「线性」激活: a(x) = x)。\n",
    "- use_bias: 布尔值，该层是否使用偏置向量。\n",
    "- kernel_initializer: kernel 权值矩阵的初始化器 (详见 initializers)。\n",
    "- bias_initializer: 偏置向量的初始化器 (see initializers).\n",
    "- kernel_regularizer: 运用到 kernel 权值矩阵的正则化函数 (详见 regularizer)。\n",
    "- bias_regularizer: 运用到偏置向的的正则化函数 (详见 regularizer)。\n",
    "- activity_regularizer: 运用到层的输出的正则化函数 (它的 \"activation\")。 (详见 regularizer)。\n",
    "- kernel_constraint: 运用到 kernel 权值矩阵的约束函数 (详见 constraints)。\n",
    "- bias_constraint: 运用到偏置向量的约束函数 (详见 constraints)。\n",
    "\n",
    "### 输入尺寸\n",
    "nD 张量，尺寸: (batch_size, ..., input_dim)。 最常见的情况是一个尺寸为 (batch_size, input_dim) 的 2D 输入。\n",
    "\n",
    "### 输出尺寸\n",
    "nD 张量，尺寸: (batch_size, ..., units)。 例如，对于尺寸为 (batch_size, input_dim) 的 2D 输入， 输出的尺寸为 (batch_size, units)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T02:19:58.822656Z",
     "start_time": "2020-08-23T02:19:58.760231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 32)                1056      \n",
      "=================================================================\n",
      "Total params: 1,600\n",
      "Trainable params: 1,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 作为 Sequential 模型的第一层\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(16,)))\n",
    "# 现在模型就会以尺寸为 (*, 16) 的数组作为输入，\n",
    "# 其输出数组的尺寸为 (*, 32)\n",
    "\n",
    "# 在第一层之后，你就不再需要指定输入的尺寸了：\n",
    "model.add(Dense(32))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot\n",
    "```python\n",
    "keras.layers.Dot(axes, normalize=False)\n",
    "```\n",
    "计算两个tensor中样本的张量乘积。例如，如果两个张量a和b的shape都为（batch_size, n），则输出为形如（batch_size,1）的张量，结果张量每个batch的数据都是a[i,:]和b[i,:]的矩阵（向量）点积。\n",
    "\n",
    "### 参数\n",
    "- axes: 整数或整数的tuple，执行乘法的轴。\n",
    "- normalize: 布尔值，是否沿执行成绩的轴做L2规范化，如果设为True，那么乘积的输出是两个样本的余弦相似性。\n",
    "- kwargs: 普通的Layer关键字参数"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
