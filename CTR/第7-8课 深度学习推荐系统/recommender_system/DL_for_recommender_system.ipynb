{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推荐系统\n",
    "背景参考：[推荐系统简介](https://blog.csdn.net/dq_dm/article/details/39755999)\n",
    "\n",
    "随着信息技术和互联网的发展，人们逐渐从信息匮乏的时代走入了信息过载(information overload)的时代。在这个时代，无论是信息消费者还是信息生产者都遇到了很大的挑战。\n",
    "\n",
    "对于信息消费者，从大量信息中找到自己感兴趣的信息是一件非常困难的事情；对于信息生产者，让自己生产的信息脱颖而出，受到广大用户的关注，也是一件非常困难的事情。推荐系统就是解决这一矛盾的重要工具。\n",
    "\n",
    "推荐系统的任务就是联系用户和信息，一方面帮助用户发现对自己有价值的信息，另一方面让信息能够展现在对它感兴趣的用户面前，从而实现信息消费者和信息生产者的双赢。（注：信息也统称为“物品”）。\n",
    "\n",
    "![](https://img-blog.csdn.net/20141003155010031?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRFFfRE0=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1、推荐系统VS搜索引擎\n",
    "\n",
    "解决信息过载的两种方法：\n",
    "\n",
    "* 1.1 搜索引擎\n",
    "\n",
    "优点：可以让用户通过搜索关键词找到自己需要的信息。\n",
    "\n",
    "缺点：（1）需要用户主动提供准确的关键词来寻找信息，当用户无法找到准确描述自己需求的关键词时，搜索引擎就无能为力了；（2）用户在使用同一个关键字搜索信息时，得到的结果是相同的；（3）信息及其传播是多样化的，而用户对信息的需求是多元化和个性化的，那么通过以搜索引擎为代表的信息检索系统获得的结果不能满足用户的个性化需求，仍然无法很好地解决信息超载问题。\n",
    "\n",
    "* 1.2 个性化推荐系统\n",
    "\n",
    "优点：（1）不需要用户提供明确的需求，它是根据用户的信息需求、兴趣等，将用户感兴趣的信息、产品等推荐给用户；（2）从物品的角度出发，推荐系统可以更好地发掘物品的长尾（long tail）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2、推荐系统的概念和定义\n",
    "\n",
    "推荐系统的定义有不少，但被广泛接受的推荐系统的概念和定义是Resnick和Varian在1997年给出的：“它是利用电子商务网站向客户提供商品信息和建议，帮助用户决定应该购买什么产品，模拟销售人员帮助客户完成购买过程”。\n",
    "\n",
    "推荐系统有3个重要的模块：用户建模模块、推荐对象建模模块、推荐算法模块。通用的推荐系统模型流程如图2所示。推荐系统把用户模型中兴趣需求信息和推荐对象模型中的特征信息匹配，同时使用相应的推荐算法进行计算筛选，找到用户可能感兴趣的推荐对象，然后推荐给用户。\n",
    "\n",
    "![](https://img-blog.csdn.net/20141003155317043?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRFFfRE0=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3、推荐算法\n",
    "\n",
    "推荐算法（或叫推荐策略）是整个推荐系统中最核心和关键的部分，在很大程度上决定了推荐系统类型和性能的优劣，推荐算法的研究是推荐系统最为繁荣的部分，大量的论文著作都关注了这个方面。目前，出现的推荐算法有很多，对其分类的标准也没有一个统一的标准，但受到大家公认的推荐算法基本包括以下几种：基于内容的推荐、协同过滤推荐、基于关联规则的推荐、基于知识的推荐、组合（混合）推荐及其他推荐。以下来介绍各种推荐策略及其优缺点。\n",
    "\n",
    "##### 3.1 基于内容的推荐\n",
    "\n",
    "基于内容的推荐（content-based recommendation）方法源于信息获取领域，是信息检索领域的重要研究内容。该方法是根据用户已经选择的对象，从推荐对象中选择其他特征相似的对象作为推荐结果。\n",
    "\n",
    "（1）这一推荐算法首先提取推荐对象的内容特征，和用户模型中的用户兴趣偏好匹配，匹配度较高的推荐对象就可作为推荐结果推荐给用户。例如在进行音乐推荐时，系统分析用户以前选择的音乐的共性，找到用户的兴趣点。然后从其他音乐中选择和用户兴趣点相似的音乐推荐给用户；\n",
    "\n",
    "（2）计算推荐对象的内容特征和用户模型中兴趣特征二者之间的相似性是该推荐策略中一个关键部分；\n",
    "\n",
    "（3）计算所得的值按其大小排序，将最靠前的若干个对象作为推荐结果呈现给用户。\n",
    "\n",
    "基于内容的推荐算法中的关键就是用户模型描述和推荐对象内容特征描述。其中对推荐对象内容进行特征提取，目前对文本内容进行特征提取方法比较成熟，如浏览页面的推荐、新闻推荐等。但网上的多媒体信息大量涌现，而对这些多媒体数据进行特征提取还有待技术支持，所以多媒体信息还没有大量用于基于内容的推荐。\n",
    "\n",
    "基于内容的推荐的优点如下：\n",
    "\n",
    "（1）简单、有效，推荐结果直观，容易理解，不需要领域知识。\n",
    "\n",
    "（2）不需要用户的历史数据，如对对象的评价等。\n",
    "\n",
    "（3）没有关于新推荐对象出现的冷启动问题。\n",
    "\n",
    "（4）没有稀疏问题。\n",
    "\n",
    "（5）比较成熟的分类学习方法能够为该方法提供支持，如数据挖掘、聚类分析等。\n",
    "\n",
    " 基于内容的推荐的缺点如下：\n",
    "\n",
    "（1）该方法的广泛应用受到了推荐对象特征提取能力的限制较为严重。因为多媒体资源 没有有效的特征提取方法，比如图像、视频、音乐等。既使文本资源，其特征提取方法也只能反映资源的一部分内容，例如，难以提取网页内容的质量，这些特征可能影响到用户的满意度。\n",
    "\n",
    "（2）很难出现新的推荐结果。推荐对象的内容特征和用户的兴趣偏好匹配才能获得推荐，用户将仅限于获得跟以前类似的推荐结果，很难为用户发现新的感兴趣的信息。\n",
    "\n",
    "（3）存在新用户出现时的冷启动问题。当新用户出现时，系统较难获得该用户的兴趣偏好，就不能和推荐对象的内容特征进行匹配，该用户将较难获得满意的推荐结果。\n",
    "\n",
    "（4）对推荐对象内容分类方法需要的数据量较大。目前，尽管分类方法很多，但构造分类器时需要的数据量巨大，给分类带来一定困难。\n",
    "\n",
    "（5）不同语言的描述的用户模型和推荐对象模型无法兼容也是基于内容推荐系统面临的又一个大的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 协同过滤推荐\n",
    "\n",
    "协同过滤推荐（collaborative filtering recommendation）是推荐算法中最成功的算法，它于20世纪90年代开始研究并促进了整个推荐系统研究的繁荣。大量论文和研究都属于该类别。比如Grundy书籍推荐系统、Tapestry邮件处理系统，Grou-plens、Ringo等推荐系统都属于该类推荐。\n",
    "\n",
    "协同过滤推荐的基本思想借鉴了日常在选购商品、选择用餐饭店、选择看哪部电影等等的方法。如果自己身边的很多朋友都选购某种商品，那么自己就会很大概率的选择该商品。或者用户喜欢某类商品，当看到和这类商品相似商品并且其他用户对此类商品评价很高时，则购买的概率就会很大。协同推荐的用户模型为用户-项目评价矩阵。\n",
    "\n",
    "协同过滤推荐一般分为两类：基于用户的协同推荐(User-based Collaborative Filtering)(或基于内存的协同推荐(Mem-ory-Based Collaborative Filtering))、基于项目的协同推荐(Item-Based Collaborative Filtering)。\n",
    "\n",
    "![](https://img-blog.csdn.net/20141003160035934?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRFFfRE0=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n",
    "\n",
    "![](https://img-blog.csdn.net/20141003155928046?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRFFfRE0=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 基于关联规则的推荐\n",
    "\n",
    "基于关联规则的推荐系统(AssociationRule一basedReeommender)是以关联规则挖掘算法为基础，把用户已购买(或者喜好)的项目作为规则头，把规则体作为待选推荐对象。\n",
    "\n",
    "##### 3.4 基于知识的推荐\n",
    "\n",
    "基于内容的过滤和协同过滤技术若没有经过足够数据的训练则其推荐质量非常低。基于知识的推荐技术不依赖客户对商品的评分数据量，而是通过推断用户的需要和偏好来作出推荐。总结查阅的文献，可将基于知识的推荐技术分为三类：数据库知识发现KDD(Knowledge Dis-covery in Database)、基于案例推理CBR(Case Based Reasoning)和知识推理KR(Knowledge Reasoning)。\n",
    "\n",
    "##### 3.5 组合（混合）推荐\n",
    "\n",
    "各种推荐方法都有各自的优缺点，在实际应用中可以针对具体问题采用推荐算法的组合进行推荐，即所谓的组合推荐。组合推荐的目的是通过组合不同的推荐算法，达到扬长避短的目的，从而产生更符合用户需求的推荐。理论上讲可以有很多种的推荐组合方法，但目前研究和应用最多的组合推荐是把基于内容的推荐和系统过滤推荐的组合。把它们组合方法根据应用场景不同而不同，主要混合思路有两种：\n",
    "\n",
    "（1）推荐结果混合：这是一种最简单的混合方法，就是分别是用两种或多种推荐方法产生推荐结果，然后采用某种算法把推荐结果进行混合而得到最终推荐。如何从众多推荐结果中选择用户需要的推荐结果成为该算法的一个重要研究点。比如采用投票机制来组合推荐结果，采用一定的标准对两者产生的推荐结果判断，从而选择其中之一，利用预测打分的线性组合进行推荐。\n",
    "\n",
    "（2）推荐算法的混合：以某种推荐算法为框架，混合另外的推荐算法，例如协同推荐的框架内混合基于内容的推荐（或相反）、基于协同推荐的框架内混合基于网络结构的推荐，社会网络分析法的推荐框架内混合基于内容的推荐，基于网络结构的推荐和基于社会网络分析法的推荐的混合等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4、推荐系统的评测指标\n",
    "\n",
    "本节将介绍各种推荐系统的评测指标。这些评测指标可用于评价推荐系统各方面的性能。这些指标有些可以定量计算，有些只能定性描述，有些可以通过离线实验计算，有些需要通过用户调查获得，还有些只能在线评测。\n",
    "\n",
    "##### 4.1  用户满意度\n",
    "\n",
    "用户作为推荐系统的参与者，其满意度是评测推荐系统的最重要指标。但是，用户满意度没有办法离线计算，只能通过用户调查或者在线实验获得。\n",
    "\n",
    "用户调查获得用户满意度主要是通过调查问卷的形式。用户对推荐系统的满意度分为不同的层次。\n",
    "\n",
    "在线系统中，用户满意度主要通过一些对用户行为的统计得到。（1）电子商务网站中，用户如果购买了推荐的商品，就表示他们在一定程度上满意，可以利用购买率度量用户的满意度（2）有些网站会通过设计一些用户反馈界面收集用户满意度，有对推荐结果满意或者不满意的反馈按钮，统计两种按钮的单击情况（3）更一般的情况下，我们可以用点击率、用户停留时间和转化率等指标度量用户的满意度\n",
    "\n",
    "##### 4.2  预测准确度\n",
    "\n",
    "预测准确度度量一个推荐系统或者推荐算法预测用户行为的能力。这个指标是最重要的推荐系统离线评测指标。\n",
    "\n",
    "（1）需要一个包含用户的历史行为记录的离线数据集\n",
    "\n",
    "（2）将该训练集通过时间分成训练集和测试集\n",
    "\n",
    "（3）通过在训练集上建立用户的行为和兴趣模型预测用户在测试集上的行为\n",
    "\n",
    "（4）计算预测行为和测试集上实际行为的重合度作为预测准确度\n",
    "\n",
    "由于离线的推荐算法有不同的研究方向，因此下面将针对不同的研究方向介绍它们的预测准确度指标。\n",
    "\n",
    "评分预测\n",
    "\n",
    "预测用户对物品评分的行为称为评分预测。\n",
    "\n",
    "评分预测的预测准确度一般通过均方根误差和平均绝对误差计算。\n",
    "\n",
    "TopN推荐\n",
    "\n",
    "主要计算召回率和准确率。准确率就是指我推荐的n个物品中有多少个是对的，其所占的比重。召回率则是指正确结果中有多少比率的物品出现在了推荐结果中。两者的不同就是前者已推荐结果个数当除数，后者已正确结果个数当除数。\n",
    "\n",
    "##### 4.3  覆盖率\n",
    "\n",
    "覆盖率最简单的定义：推荐系统能够推荐出来的物品占总物品集合的比例\n",
    "\n",
    "用来描述一个推荐系统对物品长尾的发掘能力。\n",
    "\n",
    "就是指推荐出来的结果能不能很好的覆盖所有的商品，是不是所有的商品都有被推荐的机会。最简单的方法就是计算所有被推荐的商品占物品总数的比重，当然这个比较粗糙，更精确一点的可以用信息熵和基尼系数来度量。\n",
    "\n",
    "一个好的推荐系统不仅需要有比较高的用户满意度，也要有较高的覆盖率。\n",
    "\n",
    "研究表明现在主流的推荐算法都具有马太效应（强者更强，弱者更弱）。\n",
    "\n",
    "##### 4.4  多样性\n",
    "\n",
    "为了满足用户广泛的兴趣，推荐列表需要能够覆盖用户不同的兴趣领域，即推荐结果具有多样性。\n",
    "\n",
    "多样性推荐列表的好处用一句俗话表述就是“不在一棵树上吊死”。\n",
    "\n",
    "多样性描述了推荐列表中物品两两之间的不相似性，因此多样性和相似性是对应的。可以根据物品间的相似度来计算，一个推荐列表中如果所有物品间的相似度都比较高，那么往往说明都是同一类物品，缺乏多样性。\n",
    "\n",
    "比如我看电影，我既喜欢看格斗类的电影，同时又喜欢爱装文艺，那么给我的推荐列表中就应该这两个类型的电影都有，而且得根据我爱好比例来推荐，比如我平时80%是看格斗类的，20%是看文艺类的，那么推荐结果中最好也是这个比例。\n",
    "\n",
    "##### 4.5  新颖性\n",
    "\n",
    "新颖的推荐是指给用户推荐那些他们以前没有听说过的物品\n",
    "\n",
    "在一个网站中实现新颖性的最简单方法：把那些用户之前在网站中对其有过行为的物品从推荐列表中过滤掉。\n",
    "\n",
    "不能说系统推荐的物品其实我都知道，那这样推荐系统就完全失去了存在的意义，一般都希望推荐一些用户不知道的商品或者没看过没买过的商品。方法一是取出已经看到过买过的商品，但这还不够，一般会计算推荐商品的平均流行度，因为通常越不热门的物品越会让用户觉得新颖。比如我爱周星驰，那么推荐《临岐》就很有新颖性，因为大家都不知道这是周星驰出演的。\n",
    "\n",
    "##### 4.6  惊喜度\n",
    "\n",
    "惊喜度是最近这几年推荐系统领域最热门的话题。\n",
    "\n",
    "惊喜度和新颖性是有区别的：（1）如果推荐结果和用户的历史兴趣不相似，但却让用户觉得满意，那么就可以说推荐结果的惊喜度很高；（2）推荐的新颖性仅仅取决于用户是否听说过这个推荐结果。\n",
    "\n",
    "提高推荐惊喜度需要提高推荐结果的用户满意度，同时降低推荐结果和用户历史兴趣度的相似度。\n",
    "\n",
    "##### 4.7  信任度\n",
    "\n",
    "度量推荐系统的信任度只能通过问卷调查的方式，询问用户是否信任推荐系统的推荐结果。如果用户信任推荐系统，那么往往会增加与推荐系统的互动，从而获得更好的个性化推荐。\n",
    "\n",
    "提高推荐系统的信任度的两种方法：（1）增加推荐系统的透明度（如，提供推荐解释）；（2）考虑用户的社交网络信息，利用用户的好友信息给用户做推荐，并且用好友进行推荐解释\n",
    "\n",
    "##### 4.8  实时性\n",
    "\n",
    "物品（新闻、微博等）具有很强的时效性，需要在物品还具有时效性时就将它们推荐给用户。\n",
    "\n",
    "推荐系统的实时性包括两个方面：\n",
    "\n",
    "（1）推荐系统需要实时地更新推荐列表来满足用户新的行为变化。\n",
    "\n",
    "（2）推荐系统需要能够将新加入系统的物品推荐给用户。这主要考验了推荐系统处理物品冷启动的能力。\n",
    "\n",
    "##### 4.9  健壮性\n",
    "\n",
    "任何一个能带来利益的算法系统都会被人攻击，这方面最典型的例子就是搜索引擎（作弊和反作弊斗争）。\n",
    "\n",
    "推荐系统目前也遇到了同样的作弊问题，而健壮性指标衡量了一个推荐系统抗击作弊的能力。\n",
    "\n",
    "最著名的作弊方法：行为注入攻击。\n",
    "\n",
    "算法健壮性的评测主要利用模拟攻击。\n",
    "\n",
    "在实际系统中，提高系统的健壮性，除了选择健壮性高的算法，还有以下方法：（1）设计推荐推荐系统时尽量使用代价比较高的用户行为，比如有用户购买行为和用户浏览行为，那么主要应该使用用户购买行为，因为购买需要付费；（2）在使用数据前，进行攻击检测，从而对数据进行清理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深度学习用于推荐系统\n",
    "推荐阅读：[deep learning 可以用来做推荐系统吗？](https://www.zhihu.com/question/20830906)\n",
    "\n",
    "> from 知乎 facebook推荐 宋一松 \n",
    "\n",
    "> 这个得分两方面来说。学术上，总体来说，deep learning (更确切地说，神经网络）不仅可以用来做推荐系统，还要比之前的手段表现要好。主要的优越性在于神经网络可以更好地表现稀疏的特征（sparse feature）而不需要太担心过度拟合。也正因为如此，无论是Google还是Facebook，都在逐步地把推荐系统替换成基于神经网络的（文末有附相关论文）。\n",
    "\n",
    "> 不过，既然回答这个问题了，就得说说另一方面的事情。如果说这么些年计算机科学的发展教会了我们什么道理，那就是在这个领域很少有什么绝对的更好或者更差，大多数时候都是trade-off（取舍），我们需要找的是收益与成本上最有效率的那个点。只不过技术进步会时常使得我们评价取舍的体系发生变化，从而导出不一样的结果。举例来说，互联网时代CDN和缓存的大规模出现是由于储存硬件的成本下降从而使我们更可能以空间换时间。而深度学习本身在学术上的再度复出也是由于基于算力的取舍发生了变化。\n",
    "\n",
    "> 学术的目的在于推动人类知识的边界，所以毫无疑问深度学习是未来的方向。然而在工业实践上是不是应该用深度学习做推荐系统，这取决于在每个具体情况下对收益与成本的考量。\n",
    "\n",
    "> 收益：\n",
    "\n",
    "> **1. 有没有必须上深度学习才能实现的提升？**\n",
    "> * 正如上文所说，神经网络的优越性在于对稀疏特征的表达。这对那些内容类型和用户品味五花八门的内容平台极为重要，比如Google和Facebook。而对于还处在中前期，内容和用户群调性都比较一致的产品，神经网络的独有优势并不是十分强。\n",
    "\n",
    "> **2. 是不是只要上了深度学习就能提升？**\n",
    "> * 一个明显的因素就是feature的数量和质量。如果feature上做得不够多，上了神经网络也没用。\n",
    "\n",
    "> 成本：\n",
    "> * 1. 用于开发神经网络的人力机会成本把开发资源放到对基础性工作的完善上，比如做feature上，可以有多少提升。\n",
    "> * 2. 维持额外算力的财务机会成本把钱用来推广/发工资/买好电脑来提高开发效率，会不会收效更好。\n",
    "\n",
    "> 总之，我相信神经网络一定是未来的方向，但目前，它在工业实践上是不是一个最优的方案，需要各家具体问题具体分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.MF(matrix factorization)\n",
    "代码 from [OpenLearning4DeepRecsys](https://github.com/Leavingseason/OpenLearning4DeepRecsys/tree/master/models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# %load bmf.py\n",
    "'''\n",
    "Created on Mar 3, 2017\n",
    "\n",
    "@author: v-lianji\n",
    "'''\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import data_reader \n",
    "import math\n",
    "from time import clock\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def build_model(user_indices, item_indices, rank, ratings, user_cnt, item_cnt, lr, lamb, mu, init_value):\n",
    "\t\n",
    "\t\n",
    "\tW_user = tf.Variable(tf.truncated_normal([user_cnt, rank], stddev=init_value/math.sqrt(float(rank)), mean=0), name = 'user_embedding', dtype=tf.float32)\n",
    "\tW_item = tf.Variable(tf.truncated_normal([item_cnt, rank], stddev=init_value/math.sqrt(float(rank)), mean=0), name = 'item_embedding', dtype=tf.float32)\n",
    "\t\n",
    "\tW_user_bias = tf.concat([W_user, tf.ones((user_cnt,1), dtype=tf.float32)], 1, name='user_embedding_bias')\n",
    "\tW_item_bias = tf.concat([tf.ones((item_cnt,1), dtype=tf.float32), W_item], 1, name='item_embedding_bias')\n",
    "\t\n",
    "\tuser_feature = tf.nn.embedding_lookup(W_user_bias, user_indices, name = 'user_feature')\n",
    "\titem_feature = tf.nn.embedding_lookup(W_item_bias, item_indices, name = 'item_feature')\t\n",
    "\t\n",
    "\t\n",
    "\tpreds = tf.add(tf.reduce_sum( tf.multiply(user_feature , item_feature) , 1), mu)\n",
    "\t\n",
    "\tsquare_error = tf.sqrt(tf.reduce_mean( tf.squared_difference(preds, ratings)))\n",
    "\tloss = square_error + lamb*(tf.reduce_mean(tf.nn.l2_loss(W_user)) + tf.reduce_mean(tf.nn.l2_loss(W_item)))\n",
    "\t\t\n",
    "\ttf.summary.scalar('square_error', square_error)\n",
    "\ttf.summary.scalar('loss', loss)\n",
    "\tmerged_summary = tf.summary.merge_all()\n",
    "\t#tf.global_variables_initializer()\n",
    "\ttrain_step = tf.train.GradientDescentOptimizer(lr).minimize(loss)   # tf.train.AdadeltaOptimizer(learning_rate=lr).minimize(loss)    #\n",
    "\n",
    "\treturn train_step, square_error, loss, merged_summary\n",
    "\n",
    "def grid_search_params():\n",
    "\n",
    "\tdataset = data_reader.sparse_data_repos(10000,10005)\n",
    "\tdataset.load_trainging_ratings(r'data/userbook_unique_compactid_train.txt')\n",
    "\tdataset.load_test_ratings(r'data/userbook_unique_compactid_valid.txt')\n",
    "\tdataset.load_eval_ratings(r'data/userbook_unique_compactid_test.txt')\n",
    "\tlog_file = r'BMF_log.csv'\n",
    "\t\n",
    "\twt = open(log_file,'w')\n",
    "\trank = 16\n",
    "\tlambs=[0.00003,0.00005,0.0001]\n",
    "\tbatch_sizes=[500]\n",
    "\tn_eopch=2000\n",
    "\tlrs=[0.1]\n",
    "\tinit_values = [0.01]\n",
    "\t#mu=dataset.training_ratings_score.mean()\n",
    "\tmu = np.asarray(dataset.training_ratings_score, dtype=np.float32).mean() \n",
    "\twt.write('rank,lr,lamb,mu,n_eopch,batch_size,best_train_rmse,best_test_rmse,best_eval_rmse,best_epoch,init_value,minutes\\n')\n",
    "\tfor lamb in lambs:\n",
    "\t\tfor lr in lrs:\n",
    "\t\t\tfor init_value in init_values:\n",
    "\t\t\t\tfor batch_size in batch_sizes:\n",
    "\t\t\t\t\trun_with_parameter(dataset,rank,lr,lamb,mu,n_eopch,batch_size,wt, init_value)\n",
    "\twt.close()\n",
    "\n",
    "def run_with_parameter(dataset,rank,lr,lamb,mu,n_eopch,batch_size,wt, init_value):\n",
    "\tstart = clock()\n",
    "\ttf.reset_default_graph()\n",
    "\tbest_train_rmse, best_test_rmse, best_eval_rmse, best_eopch_idx = single_run(dataset,rank,dataset.n_user,dataset.n_item,lr,lamb,mu,n_eopch,batch_size,True, init_value)\n",
    "\tend = clock()\n",
    "\twt.write('%d,%f,%f,%f,%d,%d,%f,%f,%f,%d,%f,%f\\n' %(rank,lr,lamb,mu,n_eopch,batch_size,best_train_rmse, best_test_rmse, best_eval_rmse,best_eopch_idx,init_value,(end-start)/60))\n",
    "\twt.flush()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def single_run(dataset,rank,user_cnt,item_cnt,lr,lamb,mu,n_eopch,batch_size,is_eval_on, init_value):\n",
    "\t\n",
    "\tuser_indices =  tf.placeholder(tf.int32,[None])\n",
    "\titem_indices =  tf.placeholder(tf.int32,[None])\n",
    "\tratings = tf.placeholder(tf.float32, [None])\t\n",
    "\n",
    "\n",
    "\ttrain_step, square_error, loss, merged_summary = build_model(user_indices, item_indices, rank, ratings, user_cnt, item_cnt, lr, lamb, mu, init_value)\n",
    "\t\n",
    "\tsess = tf.Session()\n",
    "\tinit = tf.global_variables_initializer()\n",
    "\tsess.run(init) \n",
    "\t\n",
    "\t#print(sess.run(user_embeddings))\n",
    "\t\n",
    "\ttrain_writer = tf.summary.FileWriter(r'logs', sess.graph)\n",
    "\t\n",
    "\tn_instances = len(dataset.training_ratings_user)\n",
    "\n",
    "\tbest_train_rmse, best_test_rmse, best_eval_rmse = -1, -1, -1\n",
    "\tbest_eopch_idx = -1 \n",
    "\tfor ite in range(n_eopch):\n",
    "\t\t#print(ite)\n",
    "\t\tstart = clock()\n",
    "\t\tfor i in range(n_instances//batch_size):\n",
    "\t\t\tstart_idx = i * batch_size \n",
    "\t\t\tend_idx = start_idx + batch_size\n",
    "\t\t\tcur_user_indices, cur_item_indices, cur_label = dataset.training_ratings_user[start_idx:end_idx], dataset.training_ratings_item[start_idx:end_idx],dataset.training_ratings_score[start_idx:end_idx]\n",
    "\t\t\t\n",
    "\t\t\tsess.run(train_step, { user_indices : cur_user_indices, item_indices : cur_item_indices, ratings : cur_label})\t\n",
    "\t\t\t\n",
    "\t\terror_traing = sess.run(square_error, { user_indices : dataset.training_ratings_user, item_indices : dataset.training_ratings_item, ratings : dataset.training_ratings_score})\n",
    "\t\terror_test = sess.run(square_error, { user_indices : dataset.test_ratings_user, item_indices : dataset.test_ratings_item, ratings : dataset.test_ratings_score})\n",
    "\t\tif is_eval_on:\n",
    "\t\t\terror_eval = sess.run(square_error, { user_indices : dataset.eval_ratings_user, item_indices : dataset.eval_ratings_item, ratings : dataset.eval_ratings_score})\n",
    "\t\telse: \n",
    "\t\t\terror_eval = -1\n",
    "\t\t\t\n",
    "\t\tif best_test_rmse<0 or best_test_rmse>error_test:\n",
    "\t\t\tbest_train_rmse, best_test_rmse, best_eval_rmse = error_traing,error_test, error_eval \n",
    "\t\t\tbest_eopch_idx = ite \n",
    "\t\telse:\n",
    "\t\t\tif ite - best_eopch_idx>10:\n",
    "\t\t\t\tbreak \n",
    "\t\t\t\n",
    "\t\tloss_traing = sess.run(loss, { user_indices : dataset.training_ratings_user, item_indices : dataset.training_ratings_item, ratings : dataset.training_ratings_score})\n",
    "\t\t#loss_test = sess.run(loss, { user_feature : test_user_feature, item_feature : test_item_feature, ratings : test_label})\n",
    "\t\tsummary = sess.run(merged_summary, { user_indices : dataset.training_ratings_user, item_indices : dataset.training_ratings_item, ratings : dataset.training_ratings_score})\n",
    "\t\ttrain_writer.add_summary(summary, ite)\n",
    "\t\tend = clock()\n",
    "\t\tprint(\"Iteration %d  RMSE(train): %f  RMSE(test): %f   RMSE(eval): %f   LOSS(train): %f  minutes: %f\" %(ite, error_traing, error_test, error_eval, loss_traing, (end-start)/60))\n",
    "\t\t\n",
    "\t\n",
    "\ttrain_writer.close()\n",
    "\t\n",
    "\treturn best_train_rmse, best_test_rmse, best_eval_rmse,best_eopch_idx\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t\n",
    "\tgrid_search_params()\n",
    "\t#run()\n",
    "\tpass "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Collaborative Deep Learning for Recommender Systems\n",
    "[paper下载地址](https://arxiv.org/pdf/1409.2944v2.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 核心思想\n",
    "推荐大致可以分为两类，基于内容推荐，基于用户行为的协同。该论文想做的是把内容和用户行为结合起来，并且使用了deep learning，希望解决content稀疏的问题。\n",
    "\n",
    "#### 具体实现\n",
    "解决content稀疏的问题，一般方法是使用stacked denoising autoencoder(SDAE)去学习item的distributed representation，输入是item content的词袋表示。\n",
    "这篇paper的做法是，结合SDAE，以及user vector，一起来拟合user-item矩阵，这个时候的loss就是sdae的loss + user-item 的loss，最小化这个loss就能完成相应的优化。\n",
    "\n",
    "![](https://img-blog.csdn.net/20161226001918229?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZ2VuaXVzbHV6aA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n",
    "\n",
    "实际预估的过程也比较清晰，item content经过sdae得到item vector，然后点乘user vector得到结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Paper的PPT介绍](http://wanghao.in/slides/CDL_slides_long.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码实现见paper作者mxnet版本，以及用keras和tensorflow实现的版本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Deep Neural Networks for YouTube Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference:[Deep Neural Networks for YouTube Recommendations论文精读](https://zhuanlan.zhihu.com/p/25343518)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 在推荐系统领域，特别是YouTube的所在视频推荐领域，主要面临三个挑战：\n",
    "> * 规模大：用户和视频的数量都很大，只能适应小规模数据集的算法就不考虑了。\n",
    "> * 更新快：youtube视频更新频率很高，每秒有小时级别的视频上传，需要在新发布视频和已有存量视频间进行balance。更新快（实时性）的另一方面的体现是用户实时行为切换很快，模型需要很好的追踪用户的实时行为。\n",
    "> * 噪音：噪音主要体现在用户的历史行为往往是稀疏的并且是不完整的，并且没有一个明确的ground truth的满意度signal，我们面对的都是noisy implicit feedback signals。噪音另一个方面就是视频本身很多数据都是非结构化的。这两点对算法的鲁棒性提出了很高的挑战。\n",
    "\n",
    ">之所以要在推荐系统中应用DNN解决问题，一个重要原因是google内部在机器学习问题上的通用solution的趋势正转移到Deep learning，系统实际部署在基于tensorflow的Google\n",
    "Brain上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 总体结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ![](https://pic1.zhimg.com/v2-533f102bd97b2b8cdf25639cfb0ab3e9_r.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 整个推荐系统分为candidate generation（召回）和Ranking（排序）两个阶段。召回阶段通过i2i/u2i/u2u/user profile等方式“粗糙”的召回候选商品，召回阶段视频的数量是百级别了；排序阶段对Matching后的视频采用更精细的特征计算user-item之间的排序分，作为最终输出推荐结果的依据。\n",
    "\n",
    "> 之所以把推荐系统划分成 召回 和 排序 两个阶段，主要是从性能方面考虑的。召回阶段面临的是百万级视频，单个视频的性能开销必须很小；而排序阶段的算法则非常消耗资源，不可能对所有视频都算一遍，实际上即便资源充足也完全没有必要，因为往往来说通不过召回粗选的视频，大部分在排序阶段排名也很低。接下来分别从召回和排序阶段展开介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 召回\n",
    "**问题建模**\n",
    "\n",
    "> 我们把推荐问题建模成一个“超大规模多分类”问题。即在时刻t，为用户U（上下文信息C）在视频库V中精准的预测出视频i的类别（每个具体的视频视为一个类别，i即为一个类别），用数学公式表达如下：\n",
    ">![](https://pic4.zhimg.com/v2-adde74b978b971e588c002038c390e0b_r.jpg)\n",
    "> 很显然上式为一个softmax多分类器的形式。向量$u\\in R^N$是<user, context>信息的高纬“embedding”，而向量$v_{j}\\in R^N$则是视频 j 的embedding向量。所以DNN的目标就是在用户信息和上下文信息为输入条件下学习用户的embedding向量u。用公式表达DNN就是在拟合函数$u = f_{DNN}(user_info, context_info)$。\n",
    "而这种超大规模分类问题上，至少要有几百万个类别，实际训练采用的是Negative Sampe，类似于word2vec的Skip-Gram方法。\n",
    "\n",
    "**模型架构**\n",
    "> ![](https://pic1.zhimg.com/v2-7f97ddd40285e08b64546e3a54a5d64a_r.jpg)\n",
    "> 整个模型架构是包含三个隐层的DNN结构。输入是用户浏览历史、搜索历史、人口统计学信息和其余上下文信息concat成的输入向量；输出分线上和离线训练两个部分。\n",
    "> 离线训练阶段输出层为softmax层，输出上面公式表达的概率。而线上则直接利用user向量查询相关商品，最重要问题是在性能。我们利用ANN/近似最近邻算法（比如类似局部敏感哈希/Locality Sensitive Hashing、KD-Tree、K-means Tree）为用户提供最相关的N个视频。\n",
    "\n",
    "**主要特征**\n",
    "> 类似于word2vec的做法，每个视频都会被embedding到固定维度的向量中。用户的观看视频历史则是通过变长的视频序列表达，最终通过加权平均（可根据重要性和时间进行加权）得到固定维度的watch vector作为DNN的输入。\n",
    "> 除历史观看视频外的其他signal：\n",
    "\n",
    "> 其实熟悉Skip-Gram方法的同学很容易看出来，把推荐问题定义为“超大规模多分类”问题的数学公式和word2vec的Skip-Gram方法的公式基本相同，所不同的是user_vec是通过DNN学习到的，而引入DNN的好处则是任意的连续特征和离散特征可以很容易添加到模型当中。同样的，推荐系统常用的矩阵分解方法虽然也能得到user_vec和item_vec，但同样是不能嵌入更多feature。\n",
    "\n",
    "> **主要特征**：\n",
    "> * **历史搜索query**：把历史搜索的query分词后的token的embedding向量进行加权平均，能够反映用户的整体搜索历史状态\n",
    "> * **人口统计学信息**：性别、年龄、地域等\n",
    "> * **其他上下文信息**：设备、登录状态等\n",
    "\n",
    "> **“Example Age” （视频上传时间）特征**\n",
    "\n",
    "> 视频网络的时效性是很重要的，每秒YouTube上都有大量新视频被上传，而对用户来讲，哪怕牺牲相关性代价，用户还是更倾向于更新的视频。当然我们不会单纯的因为一个视频新就直接推荐给用户。\n",
    "\n",
    "> 因为机器学习系统在训练阶段都是利用过去的行为预估未来，因此通常对过去的行为有个隐式的bias。视频网站视频的分布是高度非静态（non-stationary）的，但我们的推荐系统产生的视频集合在视频的分布，基本上反映的是训练所取时间段的平均的观看喜好的视频。因此我们我们把样本的 “age” 作为一个feature加入模型训练中。从下图可以很清楚的看出，加入“example age” feature后和经验分布更为match。\n",
    "> ![](https://pic2.zhimg.com/v2-83f523875baab074b340b6ccea2eba02_r.jpg)\n",
    "\n",
    "**label and context selection**\n",
    "\n",
    "> 在有监督学习问题中，最重要的选择是label了，几个设计如下：\n",
    "\n",
    "> **使用更广的数据源**：不仅仅使用推荐场景的数据进行训练，其他场景比如搜索等的数据也要用到，这样也能为推荐场景提供一些explore。\n",
    "> **为每个用户生成固定数量训练样本**：我们在实际中发现的一个practical lessons，如果为每个用户固定样本数量上限，平等的对待每个用户，避免loss被少数active用户domanate，能明显提升线上效果。\n",
    "> **抛弃序列信息**：我们在实现时尝试的是去掉序列信息，对过去观看视频/历史搜索query的embedding向量进行加权平均。这点其实违反直觉，可能原因是模型对负反馈没有很好的建模。\n",
    "> **不对称的共同浏览（asymmetric co-watch）问题**：所谓asymmetric co-watch值的是用户在浏览视频时候，往往都是序列式的，开始看一些比较流行的，逐渐找到细分的视频。下图所示图(a)是hled-out方式，利用上下文信息预估中间的一个视频；图(b)是predicting next watch的方式，则是利用上文信息，预估下一次浏览的视频。我们发现图(b)的方式在线上A/B test中表现更佳。_而实际上，传统的协同过滤类的算法，都是隐含的采用图(a)的held-out方式，忽略了不对称的浏览模式。_\n",
    "> ![](https://pic4.zhimg.com/v2-4c34494e753fa7ad6525f3533db31147_r.jpg)\n",
    "\n",
    "**不同网络深度和特征的实验**\n",
    "\n",
    "> 简单介绍下网络构建过程，采用的经典的“tower”模式搭建网络，基本同之前所示的网络架构，所有的视频和search token都embedded到256维的向量中，开始input层直接全连接到256维的softmax层，依次增加网络深度（+512-->+1024-->+2048--> ...）。\n",
    "> ![](https://pic3.zhimg.com/v2-1d5006249332a8c98b6731cb0f8c45a4_r.jpg)\n",
    "\n",
    "> 下图反映了不同网络深度（横坐标）下不同特征组合情况下的holdout-MAP（纵坐标）。可以很明显看出，增加了观看历史之外的特征很明显的提升了预测得准确率；从网络深度看，随着网络深度加大，预测准确率在提升，但继续增加第四层网络已经收益不大了。\n",
    "> ![](https://pic4.zhimg.com/v2-5b6b9563aa2e8f21518fc5cfad04c1d0_r.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 排序\n",
    "> Ranking阶段的最重要任务就是精准的预估用户对视频的喜好程度。不同于召回阶段面临的是百万级的候选视频集，Ranking阶段面对的只是百级别的商品集，因此我们可以使用更多更精细的feature来刻画视频（item）以及用户与视频（user-item）的关系。比如用户可能很喜欢某个视频，但如果list页的用的“缩略图”选择不当，用户也许不会点击，等等。\n",
    "\n",
    "> 此外，召回阶段的来源往往很多，没法直接比较。Ranking阶段另一个关键的作用是能够把不同来源的数据进行有效的ensemble。\n",
    "\n",
    "> 在目标的设定方面，单纯CTR指标是有迷惑性的，有些靠关键词吸引用户高点击的视频未必能够被播放。因此设定的目标基本与期望的观看时长相关，具体的目标调整则根据线上的A/B进行调整。\n",
    "\n",
    "**模型架构**\n",
    "\n",
    "> Ranking阶段的模型和Matching基本相似，不同的是training最后一层是一个weighted LR层，而serving阶段激励函数用的是$e^{x}$。\n",
    "> ![](https://pic4.zhimg.com/v2-33f93002d2d7f42f50e617e03ef659bd_r.jpg)\n",
    "\n",
    "**特征表达**\n",
    "> **a). Feature Engineering**：\n",
    "\n",
    "> 尽管深度学习在图像、语音和NLP等场景都能实现end-to-end的训练，没有了人工特征工程工作。然而在搜索和推荐场景，我们的很难吧原始数据直接作为FNN的输入，特征工程仍然很重要。而特征工程中最难的是如何建模用户时序行为（temporal sequence of user actions），并且关联这些行为和要rank的item。\n",
    "\n",
    "> 我们发现最重要的Signal是描述用户与商品本身或相似商品之间交互的Signal，这与Facebook在14年提出LR+GBDT模型的paper（Practical Lessons from Predicting Clicks on Ads at Facebook）中得到的结论是一致的。比如我们要度量用户对视频的喜欢，可以考虑用户与视频所在频道间的关系：\n",
    "\n",
    "> * 数量特征：浏览该频道的次数？\n",
    "> * 时间特征：比如最近一次浏览该频道距离现在的时间？\n",
    "\n",
    "> 这两个连续特征的最大好处是具备非常强的泛化能力。另外除了这两个偏正向的特征，用户对于视频所在频道的一些PV但不点击的行为，即负反馈Signal同样非常重要。\n",
    "\n",
    "\n",
    "> 另外，我们还发现，把召回阶段的信息传播到排序阶段同样能很好的提升效果，比如推荐来源和所在来源的分数。\n",
    "\n",
    "> **b). Embedding Categorical Features**\n",
    "\n",
    "> NN更适合处理连续特征，因此稀疏的特别是高基数空间的离散特征需要embedding到稠密的向量中。每个维度（比如query/user_id）都有独立的embedding空间，一般来说空间的维度基本与log(去重后值得数量)相当。实际并非为所有的id进行embedding，比如视频id，只需要按照点击排序，选择top N视频进行embedding，其余置为0向量。而对于像“过去点击的视频”这种multivalent特征，与召回阶段的处理相同，进行加权平均即可。\n",
    "\n",
    "> 另外一个值得注意的是，同维度不同feature采用的相同ID的embedding是共享的（比如“过去浏览的视频id” “seed视频id”），这样可以大大加速训练，但显然输入层仍要分别填充。\n",
    "\n",
    "\n",
    "> **c). Normalizing Continuous Features**\n",
    "\n",
    "> 众所周知，NN对输入特征的尺度和分布都是非常敏感的，实际上基本上除了Tree-Based的模型（比如GBDT/RF），机器学习的大多算法都如此。我们发现归一化方法对收敛很关键，推荐一种排序分位归一到[0,1]区间的方法，即$\\bar{x}=\\int_{-\\infty }^{x}df$，累计分位点。\n",
    "\n",
    "> 除此之外，我们还把归一化后的$\\bar{x}$的根号$\\sqrt{x}$和平方$x^{2}$作为网络输入，以期能使网络能够更容易得到特征的次线性（sub-linear）和（super-linear）超线性函数。\n",
    "\n",
    "\n",
    "**建模期望观看时长**\n",
    "\n",
    "> 我们的目标是预测期望观看时长。有点击的为正样本，有PV无点击的为负样本，正样本需要根据观看时长进行加权。因此，我们训练阶段网络最后一层用的是 weighted logistic regression。\n",
    "\n",
    "> 正样本的权重为观看时长 T_{i}，负样本权重为1。这样的话，LR学到的odds为：\n",
    "> ![](https://pic1.zhimg.com/v2-4b76c3502d11f87785fb32712ec4b623_r.jpg)\n",
    "\n",
    "> 其中N是总的样本数量，k是正样本数量，$T_{i}$是第i正样本的观看时长。一般来说，k相对N比较小，因此上式的odds可以转换成$E[T]/(1+P)$，其中P是点击率，点击率一般很小，这样odds接近于$E[T]$，即期望观看时长。因此在线上serving的inference阶段，我们采用$e^{x}$作为激励函数，就是近似的估计期望的观看时长。\n",
    "\n",
    "**不同隐层的实验**\n",
    "\n",
    "> 下图的table1是离线利用hold-out一天数据在不同NN网络结构下的结果。如果用户对模型预估高分的反而没有观看，我们认为是预测错误的观看时长。weighted, per-user loss就是预测错误观看时长占总观看时长的比例。\n",
    "\n",
    "> 我们对网络结构中隐层的宽度和深度方面都做了测试，从下图结果看增加隐层网络宽度和深度都能提升模型效果。而对于1024-->512-->256这个网络，测试的不包含归一化后根号和方式的版本，loss增加了0.2%。而如果把weighted LR替换成LR，效果下降达到4.1%。\n",
    "> ![](https://pic4.zhimg.com/v2-05b935a5fba84dac4f575dd679ddd66a_r.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实现参考paddlepaddle和tensorflow的实现方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
