1. 查看模型的信息
saved_model_cli show --dir .\saved_model\ --all
2. 基于模型信息写predict 的load
3. 基于模型信息写predict 的tf—serving


docker run -p 8501:8501 --mount \
type=bind,\
source=/root/dlp/saved_model,\
target=/models/dcn \
-e MODEL_NAME=dcn -t tensorflow/serving:1.15.0



curl -d '{"instances": [{"input0": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12367857, 0.32004258, 0.95241529, 0.13682434, 0.56921309, 0.97638547, 0.1368614, 0.79621164, 0.99523024, 0.48035478, 0.13384951, 0.55765258, 0.41585369, 0.60519948, 0.49205263, 0.09640662, 0.79793074, 0.75267708, 0.8952117, 0.83160055, 0.73796332, 0.89932472, 0.23093317, 0.18013123, 0.49722922, 0.60552245, 0.12535986, 0.3977426, 0.59993321, 0.46072406, 0.29824114, 0.15641282, 0.27497309, 0.86110401, 0.91522443, 0.74939543, 0.6659447, 0.28738114, 0.08394416, 0.31386864, 0.96873987, 0.81226766, 0.89736164, 0.02263492, 0.03782132, 0.89554018, 0.69771242, 0.66809827, 0.22263011, 0.09782888, 0.94632363, 0.76185083, 0.3285954, 0.92631555]}]}' -X POST http://172.30.31.8:8501/v1/models/dcn:predict

1. checkpoint -> saved_model
2. 采用第一种 load embed load model
3. load embed


